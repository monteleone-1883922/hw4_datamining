{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "outputId": "0a686008-683d-479c-9713-77d92adcd191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.1.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.1)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.1.3-py3-none-any.whl (777 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch) (3.9.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, lightning-utilities, docker-pycreds, gitdb, torchmetrics, GitPython, wandb, pytorch-lightning, lightning\n",
            "Successfully installed GitPython-3.1.41 docker-pycreds-0.4.0 gitdb-4.0.11 lightning-2.1.3 lightning-utilities-0.10.0 pytorch-lightning-2.1.3 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.3.0.post0 wandb-0.16.2\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Collecting polars\n",
            "  Downloading polars-0.20.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "  Attempting uninstall: polars\n",
            "    Found existing installation: polars 0.17.3\n",
            "    Uninstalling polars-0.17.3:\n",
            "      Successfully uninstalled polars-0.17.3\n",
            "Successfully installed polars-0.20.4\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch lightning numpy kaggle wandb\n",
        "!pip install polars  -U\n",
        "!pip install -U torch-geometric\n",
        "#!pip install git+https://github.com/rusty1s/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc0f2a6f-e1bb-402f-9c77-d264acaa918d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc0f2a6f-e1bb-402f-9c77-d264acaa918d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"alexxxyy47\",\"key\":\"1f2860ea591d24fc6810f02a5403dd91\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Carica il file kaggle.json\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "6faa4534c499941c",
        "outputId": "ad71b389-96c2-4d19-9a4b-1cbfe94a59d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "id": "6faa4534c499941c"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "864e92886d507f8"
      },
      "id": "864e92886d507f8"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading paysim1.zip to /content\n",
            "100% 178M/178M [00:02<00:00, 99.7MB/s]\n",
            "100% 178M/178M [00:02<00:00, 72.6MB/s]\n",
            "Archive:  paysim1.zip\n",
            "  inflating: PS_20174392719_1491204439457_log.csv  \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ealaxi/paysim1\n",
        "!unzip paysim1.zip\n",
        "!rm paysim1.zip\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "6d9167a862900129",
        "outputId": "60472ff5-dcc4-4d77-ed32-04462e95eaaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6d9167a862900129"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "import pandas as pd, sys, plotly.graph_objects as go, plotly.express as px, numpy as np, torch, random as rnd, torch.nn as nn, lightning as l, wandb as wndb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.utils import shuffle\n",
        "from torch_geometric import seed_everything\n",
        "import polars as pl\n",
        "from torch_geometric.data import Data\n",
        "import pdb\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torchmetrics\n",
        "from torch.nn import Linear, ReLU\n",
        "from torch_geometric.nn import Sequential  as GSequential, GCNConv, GATConv\n",
        "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score, BinaryPrecision, BinaryRecall"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-23T17:07:54.138381463Z",
          "start_time": "2023-12-23T17:07:50.727572469Z"
        },
        "id": "f7010a4768825241"
      },
      "id": "f7010a4768825241"
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PhGTADZ1tYC",
        "outputId": "c4fdcb1e-243a-4d55-d54a-200db910d38a"
      },
      "id": "1PhGTADZ1tYC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "# PARAMETERS\n",
        "\n",
        "DEVICE = \"cuda\"\n",
        "SEED = 42\n",
        "\n",
        "rnd.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "#torch.backends.cudnn.deterministic = False\n",
        "# torch.backends.cudnn.deterministic = True\n",
        "seed_everything(SEED)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ACCELERATOR =  \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "POS_SIZE = 150\n",
        "NEG_SIZE = 1200\n",
        "\n"
      ],
      "metadata": {
        "id": "fafd9207423f48f"
      },
      "id": "fafd9207423f48f"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "# UTILS FUNCTIONS\n",
        "\n",
        "def load_dataframe( dataset_file : str):\n",
        "    return pl.read_csv(dataset_file)\n",
        "\n",
        "\n",
        "def find_null_or_empty_records( dataframe: pd.DataFrame):\n",
        "    n = len(dataframe)\n",
        "    for index, row in dataframe.iterrows():\n",
        "        print_progress_bar(index/n)\n",
        "        # Controlla se ci sono valori nulli o vuoti nel record\n",
        "        if row.isnull().any() or any(map(lambda x: x == '', row)):\n",
        "            # Stampa il record\n",
        "            print(f\"Record con valori nulli o vuoti:\\n{row}\\n\")\n",
        "\n",
        "def print_progress_bar(percentuale, lunghezza_barra=20):\n",
        "    blocchi_compilati = int(lunghezza_barra * percentuale)\n",
        "    barra = \"[\" + \"=\" * (blocchi_compilati - 1) + \">\" + \" \" * (lunghezza_barra - blocchi_compilati) + \"]\"\n",
        "    sys.stdout.write(f\"\\r{barra} {percentuale * 100:.2f}% completo\")\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def compute_kind_inconsistence(dataframe):\n",
        "    return {\"inconsistent orig balance\": len(dataframe.query('abs(oldbalanceOrg - newbalanceOrig) != amount'))/len(dataframe),\n",
        "            \"inconsistent dest balance\": len(dataframe.query('abs(oldbalanceDest - newbalanceDest) != amount'))/len(dataframe),\n",
        "            \"zero cash transaction\": len(dataframe.query('amount == 0 '))/len(dataframe),\n",
        "            \"self-transaction\": len(dataframe.query('nameOrig == nameDest'))/len(dataframe)\n",
        "            }\n",
        "\n",
        "def plot_histogram(to_plot):\n",
        "\n",
        "\n",
        "    # Converti il dizionario in un array di valori\n",
        "    values = list(to_plot.values())\n",
        "\n",
        "    # Crea un istogramma\n",
        "    fig = go.Figure(data=[go.Bar(x=list(to_plot.keys()), y=values)])\n",
        "\n",
        "    # Mostra l'istogramma\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_categories(dataframe):\n",
        "    # Calcola la frequenza di ogni categoria nella colonna 'type'\n",
        "    counts = dataframe['type'].value_counts().reset_index()\n",
        "\n",
        "    # Rinomina le colonne\n",
        "    counts.columns = ['type', 'count']\n",
        "\n",
        "    counts['count'] = counts['count'] / counts['count'].sum()\n",
        "\n",
        "    # Crea l'istogramma con Plotly Express\n",
        "    fig = px.bar(counts, x='type', y='count', title='Istogramma delle categorie nella colonna \"type\"')\n",
        "\n",
        "    # Mostra il plot\n",
        "    fig.show()\n",
        "\n",
        "def create_name_dict(df):\n",
        "  df1 = df.select(pl.col(\"nameOrig\").alias('name'))\n",
        "  df2 = df.select(pl.col(\"nameDest\").alias('name'))\n",
        "  df = pl.concat([df1,df2])\n",
        "  df = df.unique()\n",
        "  names = list(df['name'])\n",
        "  return dict(zip(names,list(range(len(names)))))\n",
        "\n",
        "\n",
        "def divide_dataset(dataset_file,train_prc,val_prc):\n",
        "  #breakpoint()\n",
        "  dataframe = load_dataframe(dataset_file)\n",
        "  transaction_types = {\n",
        "      \"CASH_IN\": 0,\n",
        "      \"CASH_OUT\": 1,\n",
        "      \"DEBIT\": 2,\n",
        "      \"PAYMENT\": 3,\n",
        "      \"TRANSFER\": 4\n",
        "  }\n",
        "\n",
        "  dataframe = dataframe.with_columns(pl.col(\"type\").replace(transaction_types).cast(pl.Int64).alias(\"type\"),\n",
        "                                     (pl.col('step')%24).alias('step'))\n",
        "\n",
        "  id_df  = pl.DataFrame({'id': list(range(len(dataframe)))})\n",
        "\n",
        "  dataframe = pl.concat([dataframe, id_df], how=\"horizontal\")\n",
        "\n",
        "  d_neg = dataframe.filter((pl.col('amount') != 0) & (pl.col('isFraud') == 0))\n",
        "  neg_data_train = d_neg.sample(int(len(d_neg)*train_prc))\n",
        "  d_neg = d_neg.filter(~pl.col('id').is_in(neg_data_train.select(pl.col('id'))))\n",
        "\n",
        "  d_pos = dataframe.filter((pl.col('amount') != 0) & (pl.col('isFraud') == 1))\n",
        "  pos_data_train = d_pos.sample(int(len(d_pos)*train_prc))\n",
        "  d_pos = d_pos.filter(~pl.col('id').is_in(pos_data_train.select(pl.col('id'))))\n",
        "\n",
        "\n",
        "  neg_data_val = d_neg.sample(int(len(d_neg)*val_prc))\n",
        "  d_neg = d_neg.filter(~pl.col('id').is_in(neg_data_val.select(pl.col('id'))))\n",
        "\n",
        "  pos_data_val = d_pos.sample(int(len(d_pos)*val_prc))\n",
        "  d_pos = d_pos.filter(~pl.col('id').is_in(pos_data_val.select(pl.col('id'))))\n",
        "\n",
        "  neg_data_train = neg_data_train.select(pl.exclude('id'))\n",
        "  pos_data_train = pos_data_train.select(pl.exclude('id'))\n",
        "\n",
        "  neg_data_val = neg_data_val.select(pl.exclude('id'))\n",
        "  pos_data_val = pos_data_val.select(pl.exclude('id'))\n",
        "\n",
        "  d_neg = d_neg.select(pl.exclude('id'))\n",
        "  d_pos = d_pos.select(pl.exclude('id'))\n",
        "\n",
        "  return (neg_data_train, pos_data_train), (neg_data_val, pos_data_val), (d_neg,d_pos )\n",
        "\n",
        "def list_to_dataframe(data):\n",
        "  rows = []\n",
        "  for row in data:\n",
        "    el = {\n",
        "        'step': row[0],\n",
        "        'type': int(row[1]),\n",
        "        'amount': row[2] ,\n",
        "        'nameOrig': row[3],\n",
        "        'oldbalanceOrg': row[4],\n",
        "        'newbalanceOrig': row[5],\n",
        "        'nameDest': row[6],\n",
        "        'oldbalanceDest': row[7],\n",
        "        'newbalanceDest': row[8],\n",
        "        'isFraud': row[9],\n",
        "        'isFlaggedFraud': row[10]\n",
        "     }\n",
        "    rows.append(el)\n",
        "  return pl.DataFrame(rows)\n",
        "\n",
        "\n",
        "\n",
        "def collate( data ):\n",
        "  if type(data) is list:\n",
        "  #breakpoint()\n",
        "    data = list_to_dataframe(data)\n",
        "\n",
        "\n",
        "  name_d = create_name_dict(data)\n",
        "  x = torch.tensor([[1] if y.startswith(\"M\") else [0] for y in name_d.keys()], dtype=torch.float).to(DEVICE)\n",
        "  data = data.with_columns(pl.col('nameOrig').replace(name_d).cast(pl.Int64).alias('nameOrig'), pl.col('nameDest').replace(name_d).cast(pl.Int64).alias('nameDest'))\n",
        "  edges = data.select(pl.col('nameOrig','nameDest'))\n",
        "  edge_index = torch.tensor(edges.to_numpy(), dtype=torch.int64).t().contiguous().to(DEVICE)\n",
        "  y = torch.tensor(data.select(pl.col('isFraud')).to_numpy(), dtype=torch.float).to(DEVICE)\n",
        "  #edge_attr =  torch.tensor(data.select(pl.col('amount')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "  edge_attr =  torch.tensor(data.select(pl.col('step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest')).to_numpy(), dtype=torch.float).to(DEVICE)\n",
        "  data_graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "  return data, data_graph\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-23T17:07:57.977091136Z",
          "start_time": "2023-12-23T17:07:57.964383768Z"
        },
        "id": "eb7be9ce4b817dc4"
      },
      "id": "eb7be9ce4b817dc4"
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = load_dataframe(\"PS_20174392719_1491204439457_log.csv\")\n",
        "dataframe = dataframe.cast({\"isFraud\": pl.Int8})"
      ],
      "metadata": {
        "id": "fPZrGuaresNB"
      },
      "id": "fPZrGuaresNB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = create_name_dict(dataframe)"
      ],
      "metadata": {
        "id": "LczdXps_Aa6j"
      },
      "id": "LczdXps_Aa6j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(d.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H65bttAgAlsx",
        "outputId": "075b9c5e-8875-4dea-8732-503da0840572"
      },
      "id": "H65bttAgAlsx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9073900"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "divide_dataset(\"PS_20174392719_1491204439457_log.csv\",0.7,0.1)"
      ],
      "metadata": {
        "id": "9S-SzATpiH0T",
        "outputId": "24aa0759-014d-43c9-baa8-750b74eed096",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9S-SzATpiH0T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((shape: (4_448_084, 11)\n",
              "  ┌──────┬──────┬───────────┬─────────────┬───┬──────────────┬──────────────┬─────────┬──────────────┐\n",
              "  │ step ┆ type ┆ amount    ┆ nameOrig    ┆ … ┆ oldbalanceDe ┆ newbalanceDe ┆ isFraud ┆ isFlaggedFra │\n",
              "  │ ---  ┆ ---  ┆ ---       ┆ ---         ┆   ┆ st           ┆ st           ┆ ---     ┆ ud           │\n",
              "  │ i64  ┆ str  ┆ f64       ┆ str         ┆   ┆ ---          ┆ ---          ┆ i64     ┆ ---          │\n",
              "  │      ┆      ┆           ┆             ┆   ┆ f64          ┆ f64          ┆         ┆ i64          │\n",
              "  ╞══════╪══════╪═══════════╪═════════════╪═══╪══════════════╪══════════════╪═════════╪══════════════╡\n",
              "  │ 16   ┆ 4    ┆ 2.7249e6  ┆ C111177078  ┆ … ┆ 0.0          ┆ 2.8515e6     ┆ 0       ┆ 0            │\n",
              "  │ 15   ┆ 0    ┆ 122161.91 ┆ C348307229  ┆ … ┆ 2018844.6    ┆ 1.1433e6     ┆ 0       ┆ 0            │\n",
              "  │ 16   ┆ 4    ┆ 115519.78 ┆ C106220047  ┆ … ┆ 0.0          ┆ 126625.6     ┆ 0       ┆ 0            │\n",
              "  │ 20   ┆ 1    ┆ 268483.68 ┆ C1882402481 ┆ … ┆ 831168.67    ┆ 1.0997e6     ┆ 0       ┆ 0            │\n",
              "  │ …    ┆ …    ┆ …         ┆ …           ┆ … ┆ …            ┆ …            ┆ …       ┆ …            │\n",
              "  │ 15   ┆ 0    ┆ 490379.5  ┆ C1707708584 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 14   ┆ 3    ┆ 11098.07  ┆ C1463806924 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 9    ┆ 1    ┆ 220389.68 ┆ C78666543   ┆ … ┆ 161079.29    ┆ 381468.97    ┆ 0       ┆ 0            │\n",
              "  │ 18   ┆ 1    ┆ 246579.38 ┆ C676420227  ┆ … ┆ 1.1128e6     ┆ 1.3594e6     ┆ 0       ┆ 0            │\n",
              "  └──────┴──────┴───────────┴─────────────┴───┴──────────────┴──────────────┴─────────┴──────────────┘,\n",
              "  shape: (5_737, 11)\n",
              "  ┌──────┬──────┬───────────┬─────────────┬───┬──────────────┬──────────────┬─────────┬──────────────┐\n",
              "  │ step ┆ type ┆ amount    ┆ nameOrig    ┆ … ┆ oldbalanceDe ┆ newbalanceDe ┆ isFraud ┆ isFlaggedFra │\n",
              "  │ ---  ┆ ---  ┆ ---       ┆ ---         ┆   ┆ st           ┆ st           ┆ ---     ┆ ud           │\n",
              "  │ i64  ┆ str  ┆ f64       ┆ str         ┆   ┆ ---          ┆ ---          ┆ i64     ┆ ---          │\n",
              "  │      ┆      ┆           ┆             ┆   ┆ f64          ┆ f64          ┆         ┆ i64          │\n",
              "  ╞══════╪══════╪═══════════╪═════════════╪═══╪══════════════╪══════════════╪═════════╪══════════════╡\n",
              "  │ 13   ┆ 1    ┆ 1.9467e6  ┆ C1573457195 ┆ … ┆ 0.0          ┆ 1.9467e6     ┆ 1       ┆ 0            │\n",
              "  │ 9    ┆ 1    ┆ 382960.64 ┆ C749254504  ┆ … ┆ 1.6391e6     ┆ 2.0221e6     ┆ 1       ┆ 0            │\n",
              "  │ 6    ┆ 4    ┆ 22025.14  ┆ C1423921623 ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 18   ┆ 1    ┆ 3.5697e6  ┆ C2012983997 ┆ … ┆ 0.0          ┆ 3.5697e6     ┆ 1       ┆ 0            │\n",
              "  │ …    ┆ …    ┆ …         ┆ …           ┆ … ┆ …            ┆ …            ┆ …       ┆ …            │\n",
              "  │ 2    ┆ 4    ┆ 3.2842e6  ┆ C103236252  ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 10   ┆ 4    ┆ 1.2313e6  ┆ C2120061745 ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 19   ┆ 4    ┆ 2.0448e6  ┆ C1216424178 ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 9    ┆ 1    ┆ 3.2952e6  ┆ C1587398978 ┆ … ┆ 0.0          ┆ 4.0029e6     ┆ 1       ┆ 0            │\n",
              "  └──────┴──────┴───────────┴─────────────┴───┴──────────────┴──────────────┴─────────┴──────────────┘),\n",
              " (shape: (190_632, 11)\n",
              "  ┌──────┬──────┬───────────┬─────────────┬───┬──────────────┬──────────────┬─────────┬──────────────┐\n",
              "  │ step ┆ type ┆ amount    ┆ nameOrig    ┆ … ┆ oldbalanceDe ┆ newbalanceDe ┆ isFraud ┆ isFlaggedFra │\n",
              "  │ ---  ┆ ---  ┆ ---       ┆ ---         ┆   ┆ st           ┆ st           ┆ ---     ┆ ud           │\n",
              "  │ i64  ┆ str  ┆ f64       ┆ str         ┆   ┆ ---          ┆ ---          ┆ i64     ┆ ---          │\n",
              "  │      ┆      ┆           ┆             ┆   ┆ f64          ┆ f64          ┆         ┆ i64          │\n",
              "  ╞══════╪══════╪═══════════╪═════════════╪═══╪══════════════╪══════════════╪═════════╪══════════════╡\n",
              "  │ 11   ┆ 1    ┆ 139359.08 ┆ C1255105762 ┆ … ┆ 34016.86     ┆ 247848.43    ┆ 0       ┆ 0            │\n",
              "  │ 23   ┆ 3    ┆ 6408.04   ┆ C1658670777 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 17   ┆ 1    ┆ 509339.88 ┆ C1131111129 ┆ … ┆ 68133.41     ┆ 577473.28    ┆ 0       ┆ 0            │\n",
              "  │ 20   ┆ 3    ┆ 1748.07   ┆ C86155008   ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ …    ┆ …    ┆ …         ┆ …           ┆ … ┆ …            ┆ …            ┆ …       ┆ …            │\n",
              "  │ 17   ┆ 3    ┆ 33056.95  ┆ C2005495864 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 20   ┆ 3    ┆ 4740.3    ┆ C355775733  ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 21   ┆ 3    ┆ 7275.77   ┆ C1550253906 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 18   ┆ 4    ┆ 109528.66 ┆ C62182585   ┆ … ┆ 9038.99      ┆ 118567.66    ┆ 0       ┆ 0            │\n",
              "  └──────┴──────┴───────────┴─────────────┴───┴──────────────┴──────────────┴─────────┴──────────────┘,\n",
              "  shape: (246, 11)\n",
              "  ┌──────┬──────┬───────────┬─────────────┬───┬──────────────┬──────────────┬─────────┬──────────────┐\n",
              "  │ step ┆ type ┆ amount    ┆ nameOrig    ┆ … ┆ oldbalanceDe ┆ newbalanceDe ┆ isFraud ┆ isFlaggedFra │\n",
              "  │ ---  ┆ ---  ┆ ---       ┆ ---         ┆   ┆ st           ┆ st           ┆ ---     ┆ ud           │\n",
              "  │ i64  ┆ str  ┆ f64       ┆ str         ┆   ┆ ---          ┆ ---          ┆ i64     ┆ ---          │\n",
              "  │      ┆      ┆           ┆             ┆   ┆ f64          ┆ f64          ┆         ┆ i64          │\n",
              "  ╞══════╪══════╪═══════════╪═════════════╪═══╪══════════════╪══════════════╪═════════╪══════════════╡\n",
              "  │ 9    ┆ 1    ┆ 178503.45 ┆ C1542642988 ┆ … ┆ 382903.28    ┆ 561406.72    ┆ 1       ┆ 0            │\n",
              "  │ 2    ┆ 1    ┆ 206985.26 ┆ C1357050524 ┆ … ┆ 1372.42      ┆ 208357.68    ┆ 1       ┆ 0            │\n",
              "  │ 13   ┆ 1    ┆ 530354.58 ┆ C1119661582 ┆ … ┆ 4.7288e6     ┆ 5.2591e6     ┆ 1       ┆ 0            │\n",
              "  │ 1    ┆ 4    ┆ 286306.33 ┆ C822440427  ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ …    ┆ …    ┆ …         ┆ …           ┆ … ┆ …            ┆ …            ┆ …       ┆ …            │\n",
              "  │ 4    ┆ 1    ┆ 59841.44  ┆ C1061422162 ┆ … ┆ 0.0          ┆ 59841.44     ┆ 1       ┆ 0            │\n",
              "  │ 16   ┆ 4    ┆ 212613.29 ┆ C1424554187 ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 2    ┆ 1    ┆ 37065.55  ┆ C281192595  ┆ … ┆ 1.3963e6     ┆ 1.4334e6     ┆ 1       ┆ 0            │\n",
              "  │ 15   ┆ 1    ┆ 39713.28  ┆ C1404885898 ┆ … ┆ 1.2749e6     ┆ 1.3146e6     ┆ 1       ┆ 0            │\n",
              "  └──────┴──────┴───────────┴─────────────┴───┴──────────────┴──────────────┴─────────┴──────────────┘),\n",
              " (shape: (1_715_691, 11)\n",
              "  ┌──────┬──────┬───────────┬─────────────┬───┬──────────────┬──────────────┬─────────┬──────────────┐\n",
              "  │ step ┆ type ┆ amount    ┆ nameOrig    ┆ … ┆ oldbalanceDe ┆ newbalanceDe ┆ isFraud ┆ isFlaggedFra │\n",
              "  │ ---  ┆ ---  ┆ ---       ┆ ---         ┆   ┆ st           ┆ st           ┆ ---     ┆ ud           │\n",
              "  │ i64  ┆ str  ┆ f64       ┆ str         ┆   ┆ ---          ┆ ---          ┆ i64     ┆ ---          │\n",
              "  │      ┆      ┆           ┆             ┆   ┆ f64          ┆ f64          ┆         ┆ i64          │\n",
              "  ╞══════╪══════╪═══════════╪═════════════╪═══╪══════════════╪══════════════╪═════════╪══════════════╡\n",
              "  │ 1    ┆ 3    ┆ 9839.64   ┆ C1231006815 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 1    ┆ 3    ┆ 11668.14  ┆ C2048537720 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 1    ┆ 3    ┆ 7107.77   ┆ C154988899  ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 1    ┆ 3    ┆ 7861.64   ┆ C1912850431 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ …    ┆ …    ┆ …         ┆ …           ┆ … ┆ …            ┆ …            ┆ …       ┆ …            │\n",
              "  │ 22   ┆ 3    ┆ 8178.01   ┆ C1213413071 ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  │ 22   ┆ 0    ┆ 96239.74  ┆ C759614959  ┆ … ┆ 151109.37    ┆ 54869.63     ┆ 0       ┆ 0            │\n",
              "  │ 22   ┆ 1    ┆ 317177.48 ┆ C857156502  ┆ … ┆ 345042.13    ┆ 662219.61    ┆ 0       ┆ 0            │\n",
              "  │ 22   ┆ 3    ┆ 8634.29   ┆ C642813806  ┆ … ┆ 0.0          ┆ 0.0          ┆ 0       ┆ 0            │\n",
              "  └──────┴──────┴───────────┴─────────────┴───┴──────────────┴──────────────┴─────────┴──────────────┘,\n",
              "  shape: (2_214, 11)\n",
              "  ┌──────┬──────┬───────────┬─────────────┬───┬──────────────┬──────────────┬─────────┬──────────────┐\n",
              "  │ step ┆ type ┆ amount    ┆ nameOrig    ┆ … ┆ oldbalanceDe ┆ newbalanceDe ┆ isFraud ┆ isFlaggedFra │\n",
              "  │ ---  ┆ ---  ┆ ---       ┆ ---         ┆   ┆ st           ┆ st           ┆ ---     ┆ ud           │\n",
              "  │ i64  ┆ str  ┆ f64       ┆ str         ┆   ┆ ---          ┆ ---          ┆ i64     ┆ ---          │\n",
              "  │      ┆      ┆           ┆             ┆   ┆ f64          ┆ f64          ┆         ┆ i64          │\n",
              "  ╞══════╪══════╪═══════════╪═════════════╪═══╪══════════════╪══════════════╪═════════╪══════════════╡\n",
              "  │ 1    ┆ 1    ┆ 1.2772e6  ┆ C467632528  ┆ … ┆ 0.0          ┆ 2.4450e6     ┆ 1       ┆ 0            │\n",
              "  │ 1    ┆ 4    ┆ 35063.63  ┆ C1364127192 ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 1    ┆ 4    ┆ 25071.46  ┆ C669700766  ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 1    ┆ 1    ┆ 132842.64 ┆ C13692003   ┆ … ┆ 0.0          ┆ 132842.64    ┆ 1       ┆ 0            │\n",
              "  │ …    ┆ …    ┆ …         ┆ …           ┆ … ┆ …            ┆ …            ┆ …       ┆ …            │\n",
              "  │ 22   ┆ 1    ┆ 652993.91 ┆ C1614818636 ┆ … ┆ 0.0          ┆ 652993.91    ┆ 1       ┆ 0            │\n",
              "  │ 22   ┆ 1    ┆ 303846.74 ┆ C1148860488 ┆ … ┆ 343660.89    ┆ 647507.63    ┆ 1       ┆ 0            │\n",
              "  │ 23   ┆ 4    ┆ 850002.52 ┆ C1685995037 ┆ … ┆ 0.0          ┆ 0.0          ┆ 1       ┆ 0            │\n",
              "  │ 23   ┆ 1    ┆ 850002.52 ┆ C1280323807 ┆ … ┆ 6.5101e6     ┆ 7.3601e6     ┆ 1       ┆ 0            │\n",
              "  └──────┴──────┴───────────┴─────────────┴───┴──────────────┴──────────────┴─────────┴──────────────┘))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.columns\n"
      ],
      "metadata": {
        "id": "DWIk8pnMfq-6",
        "outputId": "c965d59a-ca4a-4d7b-dd88-a03985bf229f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DWIk8pnMfq-6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['step',\n",
              " 'type',\n",
              " 'amount',\n",
              " 'nameOrig',\n",
              " 'oldbalanceOrg',\n",
              " 'newbalanceOrig',\n",
              " 'nameDest',\n",
              " 'oldbalanceDest',\n",
              " 'newbalanceDest',\n",
              " 'isFraud',\n",
              " 'isFlaggedFraud']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataframe.filter(pl.col('amount') == 0))"
      ],
      "metadata": {
        "id": "vXbbRiBUfqc2",
        "outputId": "0a90e7fe-0402-4bd8-81fa-cd268724a108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vXbbRiBUfqc2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#| (pl.col('nameDest').str.starts_with('M'))   (abs(pl.col('oldbalanceOrg') - pl.col('newbalanceOrig') )) == abs( pl.col('oldbalanceDest') - pl.col('newbalanceDest'))) |\n",
        "print(len(dataframe.filter( (pl.col('nameDest').str.starts_with('M'))  )))\n",
        "print(len(dataframe.filter( (pl.col('nameOrig').str.starts_with('M'))  )))\n",
        "print(len(dataframe.filter( (pl.col('isFraud') == 1)  )))"
      ],
      "metadata": {
        "id": "dwWtDWBee8CQ",
        "outputId": "f7f672db-3fd3-44cc-9239-5eef8ffd01dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dwWtDWBee8CQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2151495\n",
            "0\n",
            "8213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataframe.filter( (pl.col('nameDest').str.starts_with('M'))  |   (abs(pl.col('oldbalanceOrg') - pl.col('newbalanceOrig') ) == abs( pl.col('oldbalanceDest') - pl.col('newbalanceDest')) )           )       ))"
      ],
      "metadata": {
        "id": "RADcni_LkVc7",
        "outputId": "b863524c-7075-4298-a3ef-f22d5a524398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RADcni_LkVc7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2393661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataframe.filter( (pl.col('isFraud') == 1) & (~pl.col('nameDest').str.starts_with('M'))  &   (abs(pl.col('oldbalanceOrg') - pl.col('newbalanceOrig') ) != abs( pl.col('oldbalanceDest') - pl.col('newbalanceDest')) )           )       ))"
      ],
      "metadata": {
        "id": "mYcPR5VTk3vo",
        "outputId": "ce56b942-ed01-4458-fcb4-c56c76539798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mYcPR5VTk3vo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [1, 2, 3] })"
      ],
      "metadata": {
        "id": "YK4dBJXX5wjJ"
      },
      "id": "YK4dBJXX5wjJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.sample(1))\n",
        "print(df.sample(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzkhfx486P8C",
        "outputId": "0fe5fdf4-3c63-4113-bd5d-9ec675ddf734"
      },
      "id": "gzkhfx486P8C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (1, 2)\n",
            "┌─────┬─────┐\n",
            "│ a   ┆ b   │\n",
            "│ --- ┆ --- │\n",
            "│ i64 ┆ i64 │\n",
            "╞═════╪═════╡\n",
            "│ 2   ┆ 2   │\n",
            "└─────┴─────┘\n",
            "shape: (1, 2)\n",
            "┌─────┬─────┐\n",
            "│ a   ┆ b   │\n",
            "│ --- ┆ --- │\n",
            "│ i64 ┆ i64 │\n",
            "╞═════╪═════╡\n",
            "│ 2   ┆ 2   │\n",
            "└─────┴─────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "class FraudDetectionDataset(Dataset):\n",
        "\n",
        "    def __init__(self,neg_data, pos_data,device):\n",
        "      # mean = neg_data['oldbalanceOrg'].mean()\n",
        "      # self.neg_data = neg_data.with_columns( (pl.col('oldbalanceOrg')/mean).alias('oldbalanceOrg'))\n",
        "      # mean = neg_data['newbalanceOrig'].mean()\n",
        "      # self.neg_data = self.neg_data.with_columns((pl.col('newbalanceOrig')/mean).alias('newbalanceOrig'))\n",
        "      # mean = neg_data['oldbalanceDest'].mean()\n",
        "      # self.neg_data =  self.neg_data.with_columns((pl.col('oldbalanceDest')/mean).alias('oldbalanceDest'))\n",
        "      # mean = neg_data['newbalanceDest'].mean()\n",
        "      # self.neg_data =  self.neg_data.with_columns((pl.col('newbalanceDest')/mean).alias('newbalanceDest'))\n",
        "      # mean = pos_data['oldbalanceOrg'].mean()\n",
        "      # self.pos_data = pos_data.with_columns( (pl.col('oldbalanceOrg')/mean).alias('oldbalanceOrg'))\n",
        "      # mean = pos_data['newbalanceOrig'].mean()\n",
        "      # self.pos_data = pos_data.with_columns((pl.col('newbalanceOrig')/mean).alias('newbalanceOrig'))\n",
        "      # mean = pos_data['oldbalanceDest'].mean()\n",
        "      # self.pos_data = pos_data.with_columns((pl.col('oldbalanceDest')/mean).alias('oldbalanceDest'))\n",
        "      # mean = pos_data['newbalanceDest'].mean()\n",
        "      # self.pos_data = pos_data.with_columns((pl.col('newbalanceDest')/mean).alias('newbalanceDest'))\n",
        "      self.neg_data = neg_data\n",
        "      self.pos_data = pos_data\n",
        "      self.device = device\n",
        "\n",
        "\n",
        "\n",
        "    def collate(self, data ):\n",
        "      #breakpoint()\n",
        "      data = list_to_dataframe(data)\n",
        "      pos = self.pos_data.sample(self.pos_num)\n",
        "      data = pl.concat([pos, data])\n",
        "      name_d = create_name_dict(data)\n",
        "      x = torch.tensor([[1] if y.startswith(\"M\") else [0] for y in name_d.keys()], dtype=torch.float).to(self.device)\n",
        "      data = data.with_columns(pl.col('nameOrig').replace(name_d).cast(pl.Int64).alias('nameOrig'), pl.col('nameDest').replace(name_d).cast(pl.Int64).alias('nameDest'))\n",
        "      edges = data.select(pl.col('nameOrig','nameDest'))\n",
        "      edge_index = torch.tensor(edges.to_numpy(), dtype=torch.int64).t().contiguous().to(self.device)\n",
        "      y = torch.tensor(data.select(pl.col('isFraud')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "      #edge_attr =  torch.tensor(data.select(pl.col('amount')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "      edge_attr =  torch.tensor(data.select(pl.col('step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "      data_graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "      return data, data_graph\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.neg_data.row(index)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.neg_data)\n",
        "\n",
        "    def get_dataloader(self, batch_size, pos_num):\n",
        "      self.pos_num = pos_num\n",
        "      return DataLoader(self, batch_size=batch_size, shuffle=True, collate_fn = self.collate)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-23T17:08:02.228962691Z",
          "start_time": "2023-12-23T17:08:02.217735698Z"
        },
        "id": "98664b7b7cee0491"
      },
      "id": "98664b7b7cee0491"
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionDatasetUndersampling(Dataset):\n",
        "\n",
        "    def __init__(self,neg_data, pos_data,device, neg_perc):\n",
        "      neg_data = neg_data.sample(int(len(neg_data)*neg_perc))\n",
        "\n",
        "      self.data = pl.concat([pos_data, neg_data])\n",
        "      # mean = self.data['oldbalanceOrg'].mean()\n",
        "      # self.data = self.data.with_columns( (pl.col('oldbalanceOrg')/mean).alias('oldbalanceOrg'))\n",
        "      # mean = self.data['newbalanceOrig'].mean()\n",
        "      # self.data = self.data.with_columns((pl.col('newbalanceOrig')/mean).alias('newbalanceOrig'))\n",
        "      # mean = self.data['oldbalanceDest'].mean()\n",
        "      # self.data = self.data.with_columns((pl.col('oldbalanceDest')/mean).alias('oldbalanceDest'))\n",
        "      # mean = self.data['newbalanceDest'].mean()\n",
        "      # self.data = self.data.with_columns((pl.col('newbalanceDest')/mean).alias('newbalanceDest') )\n",
        "      self.device = device\n",
        "\n",
        "\n",
        "\n",
        "    def collate(self, data ):\n",
        "      if type(data) is list:\n",
        "      #breakpoint()\n",
        "        data = list_to_dataframe(data)\n",
        "\n",
        "\n",
        "      name_d = create_name_dict(data)\n",
        "      x = torch.tensor([[1] if y.startswith(\"M\") else [0] for y in name_d.keys()], dtype=torch.float).to(self.device)\n",
        "      data = data.with_columns(pl.col('nameOrig').replace(name_d).cast(pl.Int64).alias('nameOrig'), pl.col('nameDest').replace(name_d).cast(pl.Int64).alias('nameDest'))\n",
        "      edges = data.select(pl.col('nameOrig','nameDest'))\n",
        "      edge_index = torch.tensor(edges.to_numpy(), dtype=torch.int64).t().contiguous().to(self.device)\n",
        "      y = torch.tensor(data.select(pl.col('isFraud')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "      #edge_attr =  torch.tensor(data.select(pl.col('amount')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "      edge_attr =  torch.tensor(data.select(pl.col('step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest')).to_numpy(), dtype=torch.float).to(self.device)\n",
        "      data_graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "      return data, data_graph\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.data.row(index)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def get_dataloader(self, batch_size, pos_num):\n",
        "      self.pos_num = pos_num\n",
        "      return DataLoader(self, batch_size=batch_size, shuffle=True, collate_fn = self.collate)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QtOgaI5k_UmW"
      },
      "id": "QtOgaI5k_UmW",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs, train_dataloader, val_dataloader, loss, optimizer, f1,model_name, scheduler=None):\n",
        "  best_f1 = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # Addestramento\n",
        "    model.train()\n",
        "    train_loss_epoch = []\n",
        "    i = 1\n",
        "    for batch_inputs in train_dataloader:\n",
        "\n",
        "        print_progress_bar(i/len(train_dataloader))\n",
        "        i+=1\n",
        "        outputs = model(batch_inputs)\n",
        "        train_loss = loss(outputs, batch_inputs[1].y)\n",
        "        train_loss_epoch.append(train_loss)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        if not scheduler is None:\n",
        "          scheduler.step()\n",
        "\n",
        "    val_loss, f1_score, acc, rec, prec = validate(model, val_dataloader,loss,f1)\n",
        "    if f1_score > best_f1:\n",
        "      best_f1 = f1_score\n",
        "\n",
        "      torch.save(model.state_dict(), \"models/\"+ model_name + \"_f1=\" + str(float(best_f1)) + \".pth\")\n",
        "    wndb.log({\"Training Loss\": sum(train_loss_epoch)/len(train_loss_epoch), \"f1\": f1_score, \"val loss\": val_loss, \"acc\": acc, \"rec\": rec,\"prec\": prec})\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {sum(train_loss_epoch)/len(train_loss_epoch)}, Validation Loss: {val_loss}, f1 score = {f1_score}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, dataloader, loss, f1):\n",
        "  accuracy = BinaryAccuracy().to(DEVICE)\n",
        "  precision = BinaryPrecision().to(DEVICE)\n",
        "  recall = BinaryRecall().to(DEVICE)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    val_loss_out = []\n",
        "    f1_out = []\n",
        "    rec_out = []\n",
        "    acc_out = []\n",
        "    prec_out = []\n",
        "    i=1\n",
        "    for batch_inputs in dataloader:\n",
        "      print_progress_bar(i/len(dataloader))\n",
        "      i+=1\n",
        "      val_outputs = model(batch_inputs)\n",
        "      val_loss = loss(val_outputs, batch_inputs[1].y)\n",
        "      val_f1 = f1(val_outputs, batch_inputs[1].y)\n",
        "      val_acc = accuracy(val_outputs, batch_inputs[1].y)\n",
        "      val_rec = recall(val_outputs, batch_inputs[1].y)\n",
        "      val_prec = precision(val_outputs, batch_inputs[1].y)\n",
        "      rec_out.append(val_rec)\n",
        "      prec_out.append(val_prec)\n",
        "      acc_out.append(val_acc)\n",
        "      f1_out.append(val_f1)\n",
        "      val_loss_out.append(val_loss)\n",
        "  return sum(val_loss_out)/len(val_loss_out), sum(f1_out)/len(f1_out),sum(acc_out)/len(acc_out),sum(rec_out)/len(rec_out),sum(prec_out)/len(prec_out)\n"
      ],
      "metadata": {
        "id": "b3RSTBWHswR8"
      },
      "id": "b3RSTBWHswR8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModuleCallback(l.Callback):\n",
        "\n",
        "  def on_train_epoch_end(self, trainer, pl_module):\n",
        "\n",
        "      epoch_mean = float(torch.stack(pl_module.train_loss).mean())\n",
        "      print(\"training_epoch_mean loss = \", epoch_mean)\n",
        "      wndb.log({\"train_loss\": epoch_mean})\n",
        "      # free up the memory\n",
        "      pl_module.train_loss.clear()\n",
        "\n",
        "  def on_validation_epoch_end(self,trainer, pl_module):\n",
        "\n",
        "    mean_loss = float(torch.stack(pl_module.val_loss).mean())\n",
        "    mean_f1 = float(torch.stack(pl_module.f1_score).mean())\n",
        "    mean_acc = float(torch.stack(pl_module.acc).mean())\n",
        "    mean_prec = float(torch.stack(pl_module.prec).mean())\n",
        "    mean_rec = float(torch.stack(pl_module.rec).mean())\n",
        "\n",
        "    print(\"val_loss = \", mean_loss)\n",
        "    print(\"f1 = \", mean_f1)\n",
        "    print(\"acc = \", mean_acc)\n",
        "    print(\"prec = \", mean_prec)\n",
        "    print(\"rec = \", mean_rec)\n",
        "    wndb.log({\"val_loss\": mean_loss, \"f1\": mean_f1, \"acc\": mean_acc, \"prec\": mean_prec, \"rec\": mean_rec })\n",
        "\n"
      ],
      "metadata": {
        "id": "PstsYID6p-oq"
      },
      "id": "PstsYID6p-oq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphNN(nn.Module):\n",
        "\n",
        "  def __init__(self,in_size, out_size, h_size, deep,activation,device):\n",
        "    super(GraphNN, self).__init__()\n",
        "    self.activation = activation\n",
        "    if deep == 1:\n",
        "      self.layers = [GCNConv(in_size,out_size).to(device)]\n",
        "    else:\n",
        "      self.layers = [GCNConv(in_size,h_size).to(device)]\n",
        "      for _ in range(deep-2):\n",
        "        self.layers.append(GCNConv(h_size,h_size).to(device))\n",
        "      self.layers.append(GCNConv(h_size,out_size).to(device))\n",
        "\n",
        "\n",
        "  def forward(self,data):\n",
        "    edge_index = data.edge_index\n",
        "    edge_attr = data.edge_attr\n",
        "    x = data.x\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = self.activation(layer(x, edge_index, edge_attr))\n",
        "\n",
        "    return self.layers[-1](x, edge_index, edge_attr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IBxtgS0KuUE0"
      },
      "id": "IBxtgS0KuUE0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearNN(nn.Module):\n",
        "  def __init__(self,in_size, out_size, h_size, deep,activation):\n",
        "    super(LinearNN, self).__init__()\n",
        "    if deep == 1:\n",
        "      layers = [nn.Linear(in_size,out_size), activation]\n",
        "    else:\n",
        "      layers = [nn.Linear(in_size,h_size), activation]\n",
        "      for _ in range(deep-2):\n",
        "        layers.append(nn.Linear(h_size,h_size))\n",
        "        layers.append(activation)\n",
        "      layers.append(nn.Linear(h_size,out_size))\n",
        "    self.linear = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,data):\n",
        "    return self.linear(data)"
      ],
      "metadata": {
        "id": "UNMvHgXxuetm"
      },
      "id": "UNMvHgXxuetm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionModuleFixed(l.LightningModule):\n",
        "\n",
        "  def __init__(self,g_in_size,g_h_size,g_out_size,in_size,h_size,out_size, lr, wd, device):\n",
        "    super(FraudDetectionModule, self).__init__()\n",
        "    self.device_used = device\n",
        "    self.gnn1 = GCNConv(g_in_size,g_h_size).to(device)\n",
        "    self.gnn2 = GCNConv(g_h_size,g_out_size).to(device)\n",
        "    self.classifier = nn.Sequential(nn.Linear(in_size,h_size),nn.ReLU(),nn.Linear(h_size,out_size))\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "    self.accuracy = BinaryAccuracy()\n",
        "    self.precision = BinaryPrecision()\n",
        "    self.recall = BinaryRecall()\n",
        "    self.f1 = BinaryF1Score()\n",
        "    self.lr = lr\n",
        "    self.wd = wd\n",
        "    self.acc = []\n",
        "    self.prec = []\n",
        "    self.rec = []\n",
        "    self.f1_score = []\n",
        "    self.train_loss = []\n",
        "    self.val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,data):\n",
        "    #breakpoint()\n",
        "\n",
        "    edge_index = data[1].edge_index\n",
        "    edge_attr = data[1].edge_attr\n",
        "    x = data[1].x\n",
        "    train_edges = data[0]\n",
        "\n",
        "\n",
        "    train_features = torch.tensor(train_edges.select(pl.col('step','type','amount')).to_numpy(), dtype=torch.float ).to(self.device_used)\n",
        "\n",
        "    x = self.relu(self.gnn1(x, edge_index, edge_attr))\n",
        "    x = self.relu(self.gnn2(x, edge_index, edge_attr))\n",
        "\n",
        "    from_nodes = torch.nan_to_num(x.squeeze()[edge_index[0,:].squeeze()])\n",
        "    dest_nodes = torch.nan_to_num(x.squeeze()[edge_index[1,:].squeeze()])\n",
        "\n",
        "    to_classify = torch.cat((from_nodes,dest_nodes,train_features), dim=1)\n",
        "\n",
        "    out = self.classifier(to_classify)\n",
        "    return self.sigmoid(out)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "\n",
        "    z = self.forward(batch)\n",
        "    y = batch[1].y\n",
        "\n",
        "    loss = self.loss(z,y)\n",
        "    self.train_loss.append(loss)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    with torch.no_grad():\n",
        "      #breakpoint()\n",
        "\n",
        "      #print(\"validation\")\n",
        "\n",
        "      z = self.forward(batch)\n",
        "\n",
        "      #breakpoint()\n",
        "      val_loss = self.loss(z,batch[1].y)\n",
        "      acc = self.accuracy(z, batch[1].y)\n",
        "      prec = self.precision(z, batch[1].y)\n",
        "      rec = self.recall(z, batch[1].y)\n",
        "      f1 = self.f1(z,batch[1].y)\n",
        "\n",
        "      self.acc.append(acc)\n",
        "      self.prec.append(prec)\n",
        "      self.rec.append(rec)\n",
        "      self.f1_score.append(f1)\n",
        "      self.val_loss.append(val_loss)\n",
        "\n",
        "      #wndb.log({\"val_loss\": val_loss,\"f1-score\":f1})\n",
        "      self.log_dict({\"val_loss\": val_loss,\"f1-score\":f1}, prog_bar=True)\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "0oEeCVwiDblo"
      },
      "id": "0oEeCVwiDblo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionModule(l.LightningModule):\n",
        "\n",
        "  def __init__(self,gnn,linear, lr, wd, device):\n",
        "    super(FraudDetectionModule, self).__init__()\n",
        "    self.device_used = device\n",
        "    self.gnn = gnn\n",
        "    self.classifier = linear\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "    self.accuracy = BinaryAccuracy()\n",
        "    self.precision = BinaryPrecision()\n",
        "    self.recall = BinaryRecall()\n",
        "    self.f1 = BinaryF1Score()\n",
        "    self.lr = lr\n",
        "    self.wd = wd\n",
        "    self.acc = []\n",
        "    self.prec = []\n",
        "    self.rec = []\n",
        "    self.f1_score = []\n",
        "    self.train_loss = []\n",
        "    self.val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,data):\n",
        "    #breakpoint()\n",
        "    edge_index = data[1].edge_index\n",
        "\n",
        "    train_edges = data[0]\n",
        "\n",
        "\n",
        "    train_features = torch.tensor(train_edges.select(pl.col('step','type','amount')).to_numpy(), dtype=torch.float ).to(self.device_used)\n",
        "\n",
        "    x = self.relu(self.gnn(data[1]))\n",
        "\n",
        "    from_nodes = torch.nan_to_num(x.squeeze()[edge_index[0,:].squeeze()])\n",
        "    dest_nodes = torch.nan_to_num(x.squeeze()[edge_index[1,:].squeeze()])\n",
        "\n",
        "    to_classify = torch.cat((from_nodes,dest_nodes,train_features), dim=1)\n",
        "\n",
        "    out = self.classifier(to_classify)\n",
        "    return self.sigmoid(out)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "\n",
        "    z = self.forward(batch)\n",
        "    y = batch[1].y\n",
        "\n",
        "    loss = self.loss(z,y)\n",
        "    self.train_loss.append(loss)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    with torch.no_grad():\n",
        "      #breakpoint()\n",
        "\n",
        "      #print(\"validation\")\n",
        "\n",
        "      z = self.forward(batch)\n",
        "\n",
        "      #breakpoint()\n",
        "      val_loss = self.loss(z,batch[1].y)\n",
        "      acc = self.accuracy(z, batch[1].y)\n",
        "      prec = self.precision(z, batch[1].y)\n",
        "      rec = self.recall(z, batch[1].y)\n",
        "      f1 = self.f1(z,batch[1].y)\n",
        "\n",
        "      self.acc.append(acc)\n",
        "      self.prec.append(prec)\n",
        "      self.rec.append(rec)\n",
        "      self.f1_score.append(f1)\n",
        "      self.val_loss.append(val_loss)\n",
        "\n",
        "      #wndb.log({\"val_loss\": val_loss,\"f1-score\":f1})\n",
        "      self.log_dict({\"val_loss\": val_loss,\"f1-score\":f1}, prog_bar=True)\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "xg6p1hXAIPxg"
      },
      "id": "xg6p1hXAIPxg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "ACCELERATOR =  \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "POS_SIZE = 200\n",
        "NEG_SIZE = 1000\n",
        "\n",
        "IN_GNN = 1\n",
        "H_GNN = 64\n",
        "OUT_GNN = 10\n",
        "DEEP_GNN = 2\n",
        "ACTIVATION_GNN = nn.ReLU()\n",
        "IN_NN = 23\n",
        "OUT_NN = 1\n",
        "H_NN = 32\n",
        "DEEP_NN = 2\n",
        "ACTIVATION_NN = nn.ReLU()\n",
        "LR = 1e-3\n",
        "WD = 1e-5"
      ],
      "metadata": {
        "id": "1FNKaurI0jIP"
      },
      "id": "1FNKaurI0jIP",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionModuleOldBasic(nn.Module):\n",
        "\n",
        "  def __init__(self,gnn_in_size, gnn_out_size, linear_in_size, linear_out_size, device):\n",
        "    super(FraudDetectionModuleOld, self).__init__()\n",
        "    self.gnn = GCNConv(gnn_in_size,gnn_out_size)\n",
        "    self.classifier = nn.Linear(linear_in_size, linear_out_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self,data):\n",
        "    #breakpoint()\n",
        "    edge_index = data[1].edge_index\n",
        "    edge_attr = data[1].edge_attr\n",
        "    x = data[1].x\n",
        "    train_edges = data[0]\n",
        "\n",
        "\n",
        "    train_features = torch.tensor(train_edges.select(pl.col('step','type','amount')).to_numpy(), dtype=torch.float ).to(self.device)\n",
        "\n",
        "    x = self.relu(self.gnn(x, edge_index, edge_attr))\n",
        "\n",
        "    from_nodes = torch.nan_to_num(x.squeeze()[edge_index[0,:].squeeze()])\n",
        "    dest_nodes = torch.nan_to_num(x.squeeze()[edge_index[1,:].squeeze()])\n",
        "\n",
        "    to_classify = torch.cat((from_nodes,dest_nodes,train_features), dim=1)\n",
        "\n",
        "    out = self.classifier(to_classify)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "USlHaSRjswJh"
      },
      "id": "USlHaSRjswJh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionModuleOld(nn.Module):\n",
        "\n",
        "  def __init__(self, device, dropout):\n",
        "    super(FraudDetectionModuleOld, self).__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.gnn = GCNConv(1,128)\n",
        "    #self.gnn1 = GCNConv(128,128)\n",
        "    self.gnn2 = GCNConv(128,64)\n",
        "    self.linear =  nn.Linear(135, 128)\n",
        "    self.linear2 = nn.Linear(128, 128)\n",
        "    self.classifier = nn.Linear(128, 1)\n",
        "    #self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.device = device\n",
        "\n",
        "\n",
        "  def forward(self,data):\n",
        "    #breakpoint()\n",
        "    edge_index = data[1].edge_index\n",
        "    edge_attr = data[1].edge_attr\n",
        "    x = data[1].x\n",
        "    train_edges = data[0]\n",
        "\n",
        "\n",
        "\n",
        "    train_features = torch.tensor(train_edges.select(pl.col('step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest')).to_numpy(), dtype=torch.float ).to(self.device)\n",
        "\n",
        "    x = self.relu(self.gnn(x, edge_index, edge_attr))\n",
        "    x = self.dropout(x)\n",
        "    # x = self.relu(self.gnn1(x, edge_index, edge_attr))\n",
        "    # x = self.dropout(x)\n",
        "    x = self.relu(self.gnn2(x, edge_index, edge_attr))\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    from_nodes = torch.nan_to_num(x.squeeze()[edge_index[0,:].squeeze()])\n",
        "    dest_nodes = torch.nan_to_num(x.squeeze()[edge_index[1,:].squeeze()])\n",
        "\n",
        "    to_classify = torch.cat((from_nodes,dest_nodes,train_features), dim=1)\n",
        "    to_classify = self.relu(self.linear(to_classify))\n",
        "    to_classify = self.dropout(to_classify)\n",
        "    to_classify = self.relu(self.linear2(to_classify))\n",
        "    to_classify = self.dropout(to_classify)\n",
        "\n",
        "    out = self.classifier(to_classify)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "xRAW7Su4MJXE"
      },
      "id": "xRAW7Su4MJXE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionModuleConv(nn.Module):\n",
        "\n",
        "  def __init__(self, device, dropout):\n",
        "    super(FraudDetectionModuleConv, self).__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.gnn = GATConv(1,128,edge_dim=7)\n",
        "    self.gnn1 = GATConv(128,128,edge_dim=7)\n",
        "    self.gnn2 = GATConv(128,64,edge_dim=7)#,heads=2)\n",
        "    self.linear =  nn.Linear(128 + 7, 128)\n",
        "    self.linear2 = nn.Linear(128, 128)\n",
        "    self.classifier = nn.Linear(128, 1)\n",
        "    #self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.device = device\n",
        "\n",
        "\n",
        "  def forward(self,x, edge_index,edge_weight ):\n",
        "    #data = collate(pl.from_pandas(data))\n",
        "\n",
        "    #breakpoint()\n",
        "    # edge_index = data[1].edge_index\n",
        "    # edge_attr = data[1].edge_attr\n",
        "    # x = data[1].x\n",
        "    # train_edges = data[0]\n",
        "\n",
        "\n",
        "\n",
        "    # train_features = torch.tensor(train_edges.select(pl.col('step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest')).to_numpy(), dtype=torch.float ).to(self.device)\n",
        "\n",
        "    edge_attr = edge_weight\n",
        "    train_features = edge_weight\n",
        "\n",
        "\n",
        "    x = self.relu(self.gnn(x, edge_index, edge_attr))\n",
        "    x = self.dropout(x)\n",
        "    x = self.relu(self.gnn1(x, edge_index, edge_attr))\n",
        "    x = self.dropout(x)\n",
        "    x = self.relu(self.gnn2(x, edge_index, edge_attr))\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    from_nodes = torch.nan_to_num(x.squeeze()[edge_index[0,:].squeeze()])\n",
        "    dest_nodes = torch.nan_to_num(x.squeeze()[edge_index[1,:].squeeze()])\n",
        "\n",
        "    to_classify = torch.cat((from_nodes,dest_nodes,train_features), dim=1)\n",
        "    to_classify = self.relu(self.linear(to_classify))\n",
        "    to_classify = self.dropout(to_classify)\n",
        "    to_classify = self.relu(self.linear2(to_classify))\n",
        "    to_classify = self.dropout(to_classify)\n",
        "\n",
        "    out = self.classifier(to_classify)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "94mGnF45ymj1"
      },
      "id": "94mGnF45ymj1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, validation_set, test_set = divide_dataset(\"PS_20174392719_1491204439457_log.csv\",0.7,0.1)\n",
        "\n",
        "train_dataset =  FraudDetectionDataset(train_set[0], train_set[1], DEVICE)\n",
        "validation_dataset =  FraudDetectionDatasetUndersampling(validation_set[0], validation_set[1], DEVICE,1)\n",
        "test_dataset =  FraudDetectionDatasetUndersampling(test_set[0], test_set[1], DEVICE,1)\n",
        "\n",
        "train_loader = train_dataset.get_dataloader(750,274)\n",
        "validation_loader = validation_dataset.get_dataloader(1024,100)\n",
        "test_loader = test_dataset.get_dataloader(1024,100)"
      ],
      "metadata": {
        "id": "SrMOX0M9ULRG"
      },
      "id": "SrMOX0M9ULRG",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn = GraphNN(IN_GNN, OUT_GNN, H_GNN, DEEP_GNN, ACTIVATION_GNN, DEVICE)\n",
        "linear = LinearNN(IN_NN, OUT_NN, H_NN, DEEP_NN, ACTIVATION_NN)\n",
        "gnn.to(DEVICE)\n",
        "linear.to(DEVICE)\n",
        "model = FraudDetectionModule(gnn,linear,LR,WD, DEVICE)\n",
        "model.to(DEVICE)\n",
        "\n",
        "modelFixed = FraudDetectionModuleFixed(IN_GNN,H_GNN,OUT_GNN,IN_NN,H_NN,OUT_NN,LR,WD,DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S459-VmNUcCv",
        "outputId": "feed918c-b208-4806-8895-8a7e507190a5"
      },
      "id": "S459-VmNUcCv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FraudDetectionModule(\n",
              "  (gnn): GraphNN(\n",
              "    (activation): ReLU()\n",
              "  )\n",
              "  (classifier): LinearNN(\n",
              "    (linear): Sequential(\n",
              "      (0): Linear(in_features=23, out_features=32, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (sigmoid): Sigmoid()\n",
              "  (relu): ReLU()\n",
              "  (loss): BCEWithLogitsLoss()\n",
              "  (accuracy): BinaryAccuracy()\n",
              "  (precision): BinaryPrecision()\n",
              "  (recall): BinaryRecall()\n",
              "  (f1): BinaryF1Score()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE\n",
        "\n",
        "trainer = l.Trainer(deterministic=True, max_epochs=40, accelerator=ACCELERATOR, callbacks=[ModuleCallback()])\n"
      ],
      "metadata": {
        "id": "yltRxkgR3Kk9",
        "outputId": "ad94a0d0-d4e3-45ab-de9e-7ad424a0a2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yltRxkgR3Kk9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "wndb.init(\n",
        "    project=\"datamining-hw4\",\n",
        "\n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"learning_rate\": LR ,\n",
        "    \"weight decay\": WD\n",
        "    })\n",
        "\n",
        "\n",
        "trainer.fit(model, train_loader, validation_loader)\n",
        "\n",
        "wndb.finish()"
      ],
      "metadata": {
        "id": "3Y2C4ZZXLPGH"
      },
      "id": "3Y2C4ZZXLPGH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FraudDetectionModuleConv( DEVICE, 0)\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4blJdUTtAsOq",
        "outputId": "95cb0500-0608-4e5f-94ff-3dac2dd562fe"
      },
      "id": "4blJdUTtAsOq",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FraudDetectionModuleConv(\n",
              "  (dropout): Dropout(p=0, inplace=False)\n",
              "  (gnn): GATConv(1, 128, heads=1)\n",
              "  (gnn1): GATConv(128, 128, heads=1)\n",
              "  (gnn2): GATConv(128, 64, heads=1)\n",
              "  (linear): Linear(in_features=135, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('GAT3_model_f1=0.6326690316200256.pth', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjhq5l6vSUrg",
        "outputId": "f5544bc2-9f0d-47f0-f186-566de06181cc"
      },
      "id": "Kjhq5l6vSUrg",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, f1_score, acc, rec, prec = validate(model,test_loader,nn.BCEWithLogitsLoss(),torchmetrics.classification.BinaryF1Score().to(DEVICE))\n",
        "\n",
        "# (tensor(0.0055, device='cuda:0'),\n",
        "#  tensor(0.6112, device='cuda:0'),\n",
        "#  tensor(0.9992, device='cuda:0'),\n",
        "#  tensor(0.7349, device='cuda:0'),\n",
        "#  tensor(0.5518, device='cuda:0'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yss4HuGPTmif",
        "outputId": "f402e988-f588-4408-afea-fc8f8c8b4fb4"
      },
      "id": "Yss4HuGPTmif",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===================>] 100.00% completo"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0055, device='cuda:0'),\n",
              " tensor(0.6112, device='cuda:0'),\n",
              " tensor(0.9992, device='cuda:0'),\n",
              " tensor(0.7349, device='cuda:0'),\n",
              " tensor(0.5518, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTpYHqtsDtNM",
        "outputId": "5a7f46d5-0992-4b6e-af1f-00647eb81829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QTpYHqtsDtNM",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from torch_geometric.explain import GNNExplainer, AttentionExplainer\n",
        "from torch_geometric.explain import Explainer, ModelConfig\n"
      ],
      "metadata": {
        "id": "baRPqEcQpZz9"
      },
      "id": "baRPqEcQpZz9",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_input = next(iter(train_loader))\n",
        "\n",
        "x = my_input[1].x\n",
        "edge_index = my_input[1].edge_index\n",
        "edge_weight = my_input[1].edge_attr\n",
        "y = torch.tensor(my_input[0].select(pl.col('isFraud')).to_numpy(), dtype=torch.float)\n",
        "\n",
        "explainer_att = AttentionExplainer()\n",
        "config = ModelConfig(\"binary_classification\",\"edge\", \"raw\")\n",
        "\n",
        "edge_mask = torch.zeros(x.shape[0], dtype=torch.bool)\n",
        "edge_mask[:10] = True\n",
        "\n",
        "\n",
        "explainer = GNNExplainer(epoch=200)#model,explainer_att,\"model\",config)\n",
        "\n",
        "explaination = explainer(model, x,  edge_index)\n"
      ],
      "metadata": {
        "id": "lJE-V3GVomQK",
        "outputId": "a7c37774-689e-41b5-bc5e-9fceb52f222e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "id": "lJE-V3GVomQK",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GNNExplainer.forward() missing 1 required keyword-only argument: 'target'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-11a406390523>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGNNExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#model,explainer_att,\"model\",config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mexplaination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: GNNExplainer.forward() missing 1 required keyword-only argument: 'target'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape[0]"
      ],
      "metadata": {
        "id": "n5tq3K7PFaYL",
        "outputId": "dff52485-23eb-4ada-8980-004f6410e96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n5tq3K7PFaYL",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "OdIH7gsXVHsC",
        "outputId": "a8cd31ae-a88b-467c-86b9-35bf331ae112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OdIH7gsXVHsC",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.explain.algorithm import AttentionExplainer, GNNExplainer\n",
        "from torch_geometric.explain import Explainer, ModelConfig\n",
        "\n",
        "\n",
        "\n",
        "config = ModelConfig(\"binary_classification\",\"edge\", \"raw\")\n",
        "\n",
        "alg = AttentionExplainer()\n",
        "\n",
        "explainer = Explainer(model,alg,\"model\",model_config=config, edge_mask_type=MaskType(\"attributes\"))"
      ],
      "metadata": {
        "id": "Z5JaS-dCJjoA",
        "outputId": "adcee1bb-60b5-44e6-8145-73dc6ddc8229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "id": "Z5JaS-dCJjoA",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'edge_mask_type' needs be None or of type 'object' (got 'attributes')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1d536a783dcb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attributes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/explain/explainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, algorithm, explanation_type, model_config, node_mask_type, edge_mask_type, threshold_config)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mthreshold_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mThresholdConfig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     ):\n\u001b[0;32m---> 79\u001b[0;31m         explainer_config = ExplainerConfig(\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mexplanation_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplanation_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mnode_mask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_mask_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/explain/config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, explanation_type, node_mask_type, edge_mask_type)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0medge_mask_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0medge_mask_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMaskType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             raise ValueError(f\"'edge_mask_type' needs be None or of type \"\n\u001b[0m\u001b[1;32m    100\u001b[0m                              f\"'object' (got '{edge_mask_type.value}')\")\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'edge_mask_type' needs be None or of type 'object' (got 'attributes')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import Saliency, IntegratedGradients\n",
        "\n",
        "#my_input = next(iter(train_loader))\n",
        "#test_dataset.collate(test_dataset.data)\n",
        "# x = input[1].x\n",
        "# edge_index = input[1].edge_index\n",
        "# edge_attr = input[1].edge_attr\n",
        "\n",
        "# target = input[1].y\n",
        "\n",
        "my_input = collate(validation_dataset.data)#next(iter(test_loader))\n",
        "\n",
        "\n",
        "y = torch.tensor(my_input[0].select(pl.col('isFraud')).to_numpy(), dtype=torch.float)\n",
        "\n",
        "\n",
        "def model_forward(edge_mask, data):\n",
        "    x = data[1].x\n",
        "    edge_index = data[1].edge_index\n",
        "    edge_weight = data[1].edge_attr\n",
        "    #batch = torch.zeros(data.x.shape[0], dtype=int).to(DEVICE)\n",
        "    out = model(x, edge_index, edge_weight)#, batch, edge_mask)\n",
        "    return out\n",
        "\n",
        "\n",
        "def explain(method, data, target=0):\n",
        "    input_mask = torch.ones(data[1].edge_index.shape[1]).requires_grad_(True).to(DEVICE)\n",
        "    if method == 'ig':\n",
        "        ig = IntegratedGradients(model_forward)\n",
        "        mask = ig.attribute(input_mask, target=target,\n",
        "                            additional_forward_args=(data,),\n",
        "                            internal_batch_size=data[1].edge_index.shape[1])\n",
        "    elif method == 'saliency':\n",
        "        saliency = Saliency(model_forward)\n",
        "        mask = saliency.attribute(input_mask, target=target,\n",
        "                                  additional_forward_args=(data,))\n",
        "    else:\n",
        "        raise Exception('Unknown explanation method')\n",
        "\n",
        "    edge_mask = np.abs(mask.cpu().detach().numpy())\n",
        "    if edge_mask.max() > 0:  # avoid division by zero\n",
        "        edge_mask = edge_mask / edge_mask.max()\n",
        "    return edge_mask\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "itj4K6BpXhj2"
      },
      "id": "itj4K6BpXhj2",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(explain('ig',my_input))"
      ],
      "metadata": {
        "id": "OMkQxV-skHXj",
        "outputId": "e2b691a4-3edc-494f-a4c8-64f732ba337c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "id": "OMkQxV-skHXj",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c622dd63a18f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ig'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-f37971913ea6>\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(method, data, target)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ig'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntegratedGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         mask = ig.attribute(input_mask, target=target,\n\u001b[0m\u001b[1;32m     31\u001b[0m                             \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                             internal_batch_size=data[1].edge_index.shape[1])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minternal_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             attributions = _batch_attribution(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_utils/batching.py\u001b[0m in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mstep_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_step_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         current_attr = attr_method._attribute(\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_sizes_and_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         grads = self.gradient_func(\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaled_features_tpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# contains batch_size * #steps elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    392\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric.nn as pygnn\n",
        "import torch_geometric.data as pygdata\n",
        "import GraphSVX\n",
        "\n",
        "\n",
        "\n",
        "# Inizializza il modello, l'input e il target\n",
        "\n",
        "input = ...  # Dati di input\n",
        "target = ...  # Target\n",
        "\n",
        "# Crea il grafico PyTorch Geometric\n",
        "edge_index, _ = torch.load(input.edge_index)\n",
        "edge_weight = torch.ones(edge_index.shape[1])\n",
        "data = pygdata.Data(x=input.x, edge_index=edge_index, edge_attr=edge_weight)\n",
        "\n",
        "# Crea il grafico GraphSVX\n",
        "g = graphsvx.Graph(data)\n",
        "\n",
        "# Crea l'attributore di importanza basato su gradienti\n",
        "explainer = graphsvx.Explainer(model, g)\n",
        "\n",
        "# Esegui l'attributo\n",
        "attributions, delta = explainer.attribute(inputs=data, target=target)\n",
        "\n",
        "# Interpretazione degli output\n",
        "attributions.shape  # (num_edges,)\n",
        "delta  # Convergence delta\n",
        "\n",
        "# attributions contiene gli attributi calcolati utilizzando l'attributore basato su gradienti\n",
        "# di GraphSVX. Il delta è un indicatore della convergenza dell'algoritmo di attributo.\n",
        "# Il valore di delta dovrebbe diminuire con l'aumentare del numero di campioni n_samples.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UMfE6aZx1SIm"
      },
      "id": "UMfE6aZx1SIm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U lime"
      ],
      "metadata": {
        "id": "AYe1nCQ4sebd",
        "outputId": "58b62f70-4aa3-4b2f-a3c0-245f3739fec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AYe1nCQ4sebd",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/275.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=58e421cb2ae524beefa3ee73ec21ac0c676d4e025fa333c0b6f30821794d8e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mR8koY4bXTe3",
        "outputId": "3dfd84e5-2c0f-445e-d9ed-5211f7eb7bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mR8koY4bXTe3",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "my_input = collate(test_dataset.data)\n",
        "\n",
        "def wrapped_model(edge_weight):\n",
        "    \"\"\"\n",
        "    Takes in input a numpy array and outputs numpy array with the prediction.\n",
        "    Necessary since both shap and LIME use numpy arrays to pass parameters.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    x = my_input[1].x\n",
        "    edge_index = my_input[1].edge_index\n",
        "\n",
        "    return model(x, edge_index, edge_weight)\n",
        "\n",
        "edge_weight = my_input[1].edge_attr\n",
        "y = torch.tensor(my_input[0].select(pl.col('isFraud')).to_numpy(), dtype=torch.float)\n",
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    edge_weight, mode=\"binary_classification\",\n",
        "    class_names=[\"Median house price\"],\n",
        "    training_labels=y,\n",
        "    feature_names=['step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest'],\n",
        "    verbose=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "i23irPRhXTiy",
        "outputId": "de696318-b4c1-434e-b48c-4a7efea85fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "i23irPRhXTiy",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "min() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-09c1d052df30>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'isFraud'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_classification\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Median house price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiscretizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quartile'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 self.discretizer = QuartileDiscretizer(\n\u001b[0m\u001b[1;32m    216\u001b[0m                         \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/discretize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         BaseDiscretizer.__init__(self, data, categorical_features,\n\u001b[0m\u001b[1;32m    179\u001b[0m                                  \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                  random_state=random_state)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/discretize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_discretize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mn_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Actually number of borders (= #bins-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m     \"\"\"\n\u001b[0;32m-> 2918\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   2919\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: min() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp = lime_explainer.explain_instance(x_test[i], wrapped_model)"
      ],
      "metadata": {
        "id": "Qb0PGNfQY5P4"
      },
      "id": "Qb0PGNfQY5P4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "my_input = next(iter(train_loader))\n",
        "\n",
        "x = my_input[1].x\n",
        "edge_index = my_input[1].edge_index\n",
        "edge_weight = my_input[1].edge_attr\n",
        "y = torch.tensor(my_input[0].select(pl.col('isFraud')).to_numpy(), dtype=torch.float)\n",
        "\n",
        "\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(edge_weight, feature_names=['step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest'])\n",
        "\n",
        "\n",
        "exp = explainer.explain_instance(test[i], rf.predict_proba, num_features=2, top_labels=1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mciglPfcVBHM"
      },
      "id": "mciglPfcVBHM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_input = test_dataset.collate(test_dataset.data)"
      ],
      "metadata": {
        "id": "cWLM4mbBe06w"
      },
      "id": "cWLM4mbBe06w",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "AIVT__l1k35n",
        "outputId": "c0358d8b-a425-4d5e-d33f-ea53343307b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AIVT__l1k35n",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "my_input = collate(test_dataset.data)#next(iter(test_loader))\n",
        "\n",
        "x = my_input[1].x\n",
        "edge_index = my_input[1].edge_index\n",
        "edge_weight = my_input[1].edge_attr\n",
        "y = torch.tensor(my_input[0].select(pl.col('isFraud')).to_numpy(), dtype=torch.float)\n",
        "\n",
        "def wrapped_model(edge_weight):\n",
        "    \"\"\"\n",
        "    Takes in input a numpy array and outputs numpy array with the prediction.\n",
        "    Necessary since both shap and LIME use numpy arrays to pass parameters.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    x = my_input[1].x\n",
        "    edge_index = my_input[1].edge_index\n",
        "\n",
        "    return model(x, edge_index, edge_weight)\n",
        "\n",
        "\n",
        "explainer = shap.Explainer(wrapped_model, edge_weight, feature_names=['step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest'])\n",
        "shap_values = explainer.shap_values(edge_weight)"
      ],
      "metadata": {
        "id": "kxWw41W2fDTG",
        "outputId": "4bc25ba9-ed86-47d5-8ea6-f4470c265af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "kxWw41W2fDTG",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'Tensor' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-f7bc4a37ebb1>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'oldbalanceOrg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'newbalanceOrig'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'oldbalanceDest'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'newbalanceDest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, npermutations, main_effects, error_bounds, batch_evals, silent)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shap_values() is deprecated; use __call__().\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mexplanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpermutations\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\" Explain the output of the model on the given arguments.\n\u001b[1;32m     78\u001b[0m         \"\"\"\n\u001b[0;32m---> 79\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# evaluate the masked model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfull_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masker_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0m_convert_delta_mask_to_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0mmasked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                     \u001b[0mmasked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# get a copy that won't get overwritten by the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(explainer)"
      ],
      "metadata": {
        "id": "Ew0NmXtfdvmJ",
        "outputId": "7b1d4bd1-94a6-4cc7-c39b-5e9d1182826a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ew0NmXtfdvmJ",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shap.explainers._permutation.PermutationExplainer"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "def wrapped_model(x):\n",
        "    \"\"\"\n",
        "    Takes in input a numpy array and outputs numpy array with the prediction.\n",
        "    Necessary since both shap and LIME use numpy arrays to pass parameters.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    data = test_dataset.collate(test_dataset.data)\n",
        "    return model(data)\n",
        "\n",
        "x_test = torch.tensor(test_dataset.data.select(pl.col('step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest')).to_numpy(), dtype=torch.float)       #test_dataset.collate(test_dataset.data)\n",
        "y_test = torch.tensor(test_dataset.data.select(pl.col('isFraud')).to_numpy(), dtype=torch.float)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    x_test, mode=\"binary_classification\",\n",
        "    class_names=[\"Median house price\"],\n",
        "    training_labels=y_test,\n",
        "    feature_names=['step','type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest'],\n",
        "    verbose=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "oS_ZRGGNsbzw",
        "outputId": "447512e4-83b9-4a14-ec9d-d1f245ea4d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "id": "oS_ZRGGNsbzw",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "min() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f833635e52b0>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_classification\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Median house price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiscretizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quartile'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 self.discretizer = QuartileDiscretizer(\n\u001b[0m\u001b[1;32m    216\u001b[0m                         \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/discretize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         BaseDiscretizer.__init__(self, data, categorical_features,\n\u001b[0m\u001b[1;32m    179\u001b[0m                                  \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                  random_state=random_state)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/discretize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_discretize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mn_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Actually number of borders (= #bins-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m     \"\"\"\n\u001b[0;32m-> 2918\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   2919\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: min() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit\n"
      ],
      "metadata": {
        "id": "2aAROXjUyI2G",
        "outputId": "551d5b9f-a04c-4805-cfa9-40108aeda279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2aAROXjUyI2G",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/c-feldmann/rdkit_heatmaps\n",
        "!pip install git+https://github.com/AndMastro/edgeshaper"
      ],
      "metadata": {
        "id": "mEDExCWPIdVu",
        "outputId": "9bef60b9-da72-40c7-9805-b36ca9a80269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mEDExCWPIdVu",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/c-feldmann/rdkit_heatmaps\n",
            "  Cloning https://github.com/c-feldmann/rdkit_heatmaps to /tmp/pip-req-build-zcy4di5g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/c-feldmann/rdkit_heatmaps /tmp/pip-req-build-zcy4di5g\n",
            "  Resolved https://github.com/c-feldmann/rdkit_heatmaps to commit 3ed507ab837caaa1c10d2ae5fdf31d1cd135a777\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-heatmap==0.1) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from rdkit-heatmap==0.1) (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-heatmap==0.1) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->rdkit-heatmap==0.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->rdkit-heatmap==0.1) (1.16.0)\n",
            "Collecting git+https://github.com/AndMastro/edgeshaper\n",
            "  Cloning https://github.com/AndMastro/edgeshaper to /tmp/pip-req-build-i7e_a3kd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AndMastro/edgeshaper /tmp/pip-req-build-i7e_a3kd\n",
            "  Resolved https://github.com/AndMastro/edgeshaper to commit 59a4d25295a53a8996d68d5f0c6f57a93be2f817\n",
            "\u001b[31mERROR: git+https://github.com/AndMastro/edgeshaper does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from edgeshaper import edgeshaper\n",
        "import edgeshaper\n",
        "\n",
        "\n",
        "\n",
        "input = test_dataset.collate(test_dataset.data)\n",
        "x = input[1].x\n",
        "edge_index = input[1].edge_index\n",
        "edge_attr = input[1].edge_attr\n",
        "\n",
        "target = input[1].y\n",
        "\n",
        "explainer = edgeshaper.Edgeshaper(model,x,edge_index, edge_weight = edge_attr )\n",
        "\n",
        "attributions, delta = explainer.explain()\n",
        "\n",
        "\n",
        "# for data_tmp in train_loader:\n",
        "#   data = data_tmp\n",
        "#   break\n",
        "\n",
        "# edge_index = data[1].edge_index\n",
        "# x = data[1].x\n",
        "# device = \"cuda\" or \"cpu\"\n",
        "# target_class = data[1].y.to(dtype=torch.long) #class label for which to perform explanations\n",
        "\n",
        "# edges_explanations = edgeshaper(model, x, edge_index, M = 100, target_class = target_class, device = \"cpu\", edge_weight = data[1].edge_attr)"
      ],
      "metadata": {
        "id": "n88mxWOxyG6k",
        "outputId": "80370150-ad6a-42f7-edae-f0bbc8bf1698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n88mxWOxyG6k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1717905 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:knloycda) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7232f9029dc845a9beb8c9ad77011348"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>█▄▁</td></tr><tr><td>acc</td><td>█▄▁</td></tr><tr><td>f1</td><td>▂█▁</td></tr><tr><td>prec</td><td>▄█▁</td></tr><tr><td>rec</td><td>▁█▄</td></tr><tr><td>val loss</td><td>▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>0.01257</td></tr><tr><td>acc</td><td>0.99905</td></tr><tr><td>f1</td><td>0.57785</td></tr><tr><td>prec</td><td>0.50777</td></tr><tr><td>rec</td><td>0.73797</td></tr><tr><td>val loss</td><td>0.00555</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">misunderstood-snowflake-50</strong> at: <a href='https://wandb.ai/monteleone/datamining-hw4/runs/knloycda' target=\"_blank\">https://wandb.ai/monteleone/datamining-hw4/runs/knloycda</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240115_191108-knloycda/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:knloycda). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240115_193009-kfjoomsb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/monteleone/datamining-hw4/runs/kfjoomsb' target=\"_blank\">proud-blaze-51</a></strong> to <a href='https://wandb.ai/monteleone/datamining-hw4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/monteleone/datamining-hw4' target=\"_blank\">https://wandb.ai/monteleone/datamining-hw4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/monteleone/datamining-hw4/runs/kfjoomsb' target=\"_blank\">https://wandb.ai/monteleone/datamining-hw4/runs/kfjoomsb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===================>] 100.00% completoEpoch [1/27], Training Loss: 0.012456334196031094, Validation Loss: 0.004197665490210056, f1 score = 0.6247175931930542\n",
            "[===================>] 100.00% completoEpoch [2/27], Training Loss: 0.011865689419209957, Validation Loss: 0.004293977282941341, f1 score = 0.6326690316200256\n",
            "[===================>] 100.00% completoEpoch [3/27], Training Loss: 0.011678021401166916, Validation Loss: 0.0038685393519699574, f1 score = 0.6077175736427307\n",
            "[===================>] 100.00% completoEpoch [4/27], Training Loss: 0.011665016412734985, Validation Loss: 0.004389896988868713, f1 score = 0.6254521012306213\n",
            "[=============>      ] 74.29% completo"
          ]
        }
      ],
      "source": [
        "wndb.init(\n",
        "    project=\"datamining-hw4\",\n",
        "\n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"learning_rate\": LR ,\n",
        "    \"weight decay\": WD\n",
        "    })\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=WD)\n",
        "train(model,27,train_loader,validation_loader,nn.BCEWithLogitsLoss(), optimizer, torchmetrics.classification.BinaryF1Score().to(DEVICE),\"GAT3_model\",torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4], gamma=0.1) )\n",
        "wndb.finish()"
      ],
      "metadata": {
        "is_executing": true,
        "id": "2160990145af7a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "7232f9029dc845a9beb8c9ad77011348",
            "40016dbc2476408c9ea0ffeff4661eac",
            "04cf65bbec3b48d5a1d4ad47fe6b8112",
            "f67954fe562f4f098cc6f8138140aa61",
            "2a11c833b8804ca78f58cf1f6e2a275a",
            "72883282adcf4e76af701b773c11da71",
            "3271ba4850cb4d8486f99a0eb9b04405",
            "ebfd805b69d94c9199f2f8ddea14b14f"
          ]
        },
        "outputId": "b2f77666-0842-4885-fbfd-307b87040a2e"
      },
      "id": "2160990145af7a44"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIAXv0rkDfYT"
      },
      "id": "cIAXv0rkDfYT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "first_model =       FraudDetectionModuleOld(\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "        (gnn): GCNConv(1, 128)\n",
        "        (gnn1): GCNConv(128, 128)\n",
        "        (gnn2): GCNConv(128, 64)\n",
        "        (linear): Linear(in_features=135, out_features=128, bias=True)\n",
        "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
        "        (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
        "        (sigmoid): Sigmoid()\n",
        "        (relu): ReLU()\n",
        "      ), fake validation\n",
        "      "
      ],
      "metadata": {
        "id": "AtvvhjvgDgMv"
      },
      "id": "AtvvhjvgDgMv"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7232f9029dc845a9beb8c9ad77011348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40016dbc2476408c9ea0ffeff4661eac",
              "IPY_MODEL_04cf65bbec3b48d5a1d4ad47fe6b8112"
            ],
            "layout": "IPY_MODEL_f67954fe562f4f098cc6f8138140aa61"
          }
        },
        "40016dbc2476408c9ea0ffeff4661eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a11c833b8804ca78f58cf1f6e2a275a",
            "placeholder": "​",
            "style": "IPY_MODEL_72883282adcf4e76af701b773c11da71",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "04cf65bbec3b48d5a1d4ad47fe6b8112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3271ba4850cb4d8486f99a0eb9b04405",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebfd805b69d94c9199f2f8ddea14b14f",
            "value": 1
          }
        },
        "f67954fe562f4f098cc6f8138140aa61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a11c833b8804ca78f58cf1f6e2a275a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72883282adcf4e76af701b773c11da71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3271ba4850cb4d8486f99a0eb9b04405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfd805b69d94c9199f2f8ddea14b14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}